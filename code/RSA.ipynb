{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS1467/zitong/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchmetrics.functional import pearson_corrcoef, spearman_corrcoef\n",
    "import torch.utils.model_zoo\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import h5py\n",
    "import random\n",
    "import clip\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from neurora.rdm_corr import rdm_correlation_spearman\n",
    "import matplotlib.pyplot as plt\n",
    "from neurora.stuff import clusterbased_permutation_1d_2sided\n",
    "from scipy.stats import ttest_rel, ttest_1samp\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module for flattening input tensor to 1-D for the use in Linear modules\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module that stores the current tensor. Useful for accessing by name\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class CORblock_S(nn.Module):\n",
    "\n",
    "    scale = 4  # scale of the bottleneck convolution channels\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, times=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.times = times\n",
    "\n",
    "        self.conv_input = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.skip = nn.Conv2d(out_channels, out_channels,\n",
    "                              kernel_size=1, stride=2, bias=False)\n",
    "        self.norm_skip = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels * self.scale,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels * self.scale, out_channels * self.scale,\n",
    "                               kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.nonlin2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels * self.scale, out_channels,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.output = Identity()  # for an easy access to this block's output\n",
    "\n",
    "        # need BatchNorm for each time step for training to work well\n",
    "        for t in range(self.times):\n",
    "            setattr(self, f'norm1_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm2_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm3_{t}', nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.conv_input(inp)\n",
    "\n",
    "        for t in range(self.times):\n",
    "            if t == 0:\n",
    "                skip = self.norm_skip(self.skip(x))\n",
    "                self.conv2.stride = (2, 2)\n",
    "            else:\n",
    "                skip = x\n",
    "                self.conv2.stride = (1, 1)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = getattr(self, f'norm1_{t}')(x)\n",
    "            x = self.nonlin1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = getattr(self, f'norm2_{t}')(x)\n",
    "            x = self.nonlin2(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = getattr(self, f'norm3_{t}')(x)\n",
    "\n",
    "            x += skip\n",
    "            x = self.nonlin3(x)\n",
    "            output = self.output(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def CORnet_S():\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('V1', nn.Sequential(OrderedDict([  # this one is custom to save GPU memory\n",
    "            ('conv1', nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                            bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(64)),\n",
    "            ('nonlin1', nn.ReLU(inplace=True)),\n",
    "            ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "            ('conv2', nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1,\n",
    "                            bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(64)),\n",
    "            ('nonlin2', nn.ReLU(inplace=True)),\n",
    "            ('output', Identity())\n",
    "        ]))),\n",
    "        ('V2', CORblock_S(64, 128, times=2)),\n",
    "        ('V4', CORblock_S(128, 256, times=4)),\n",
    "        ('IT', CORblock_S(256, 512, times=2)),\n",
    "        ('decoder', nn.Sequential(OrderedDict([\n",
    "            ('avgpool', nn.AdaptiveAvgPool2d(1)),\n",
    "            ('flatten', Flatten()),\n",
    "            ('linear', nn.Linear(512, 1000)),\n",
    "            ('output', Identity())\n",
    "        ])))\n",
    "    ]))\n",
    "\n",
    "    # weight initialization\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        # nn.Linear is missing here because I originally forgot\n",
    "        # to add it during the training of this network\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    return model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, realnet, n_output):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # CORnet\n",
    "        self.realnet = realnet\n",
    "        \n",
    "        # full connected layer\n",
    "        self.fc_v1 = nn.Linear(200704, 128)\n",
    "        self.fc_v2 = nn.Linear(100352, 128)\n",
    "        self.fc_v4 = nn.Linear(50176, 128)\n",
    "        self.fc_it = nn.Linear(25088, 128)\n",
    "        self.fc = nn.Linear(512, n_output)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        \n",
    "        outputs = self.realnet(imgs)\n",
    "        \n",
    "        N = len(imgs)\n",
    "        v1_outputs = self.realnet.module.V1(imgs) # N * 64 * 56 * 56\n",
    "        v2_outputs = self.realnet.module.V2(v1_outputs) # N * 128 * 28 * 28\n",
    "        v4_outputs = self.realnet.module.V4(v2_outputs) # N * 256 * 14 * 14\n",
    "        it_outputs = self.realnet.module.IT(v4_outputs) # N * 512 * 7 * 7\n",
    "        v1_features = self.fc_v1(v1_outputs.view(N, -1))\n",
    "        v1_features = self.activation(v1_features)\n",
    "        v2_features = self.fc_v2(v2_outputs.view(N, -1))\n",
    "        v2_features = self.activation(v2_features)\n",
    "        v4_features = self.fc_v4(v4_outputs.view(N, -1))\n",
    "        v4_features = self.activation(v4_features)\n",
    "        it_features = self.fc_it(it_outputs.view(N, -1))\n",
    "        it_features = self.activation(it_features)\n",
    "        features = torch.cat((v1_features, v2_features, v4_features, it_features), dim=1)\n",
    "        features = self.fc(features)\n",
    "        \n",
    "        return outputs, features\n",
    "\n",
    "def cal_rdm(v):\n",
    "    n = v.size()[0]\n",
    "    rdm = np.zeros([n, n])\n",
    "    vec = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i > j:\n",
    "                #rdm[i, j] = 1-F.cosine_similarity(v[i], v[j], dim=0).item()\n",
    "                rdm[i, j] = 1 - pearson_corrcoef(v[i], v[j]).item()\n",
    "                rdm[j, i] = rdm[i, j]\n",
    "    return rdm\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-EEG similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data4Model(torch.utils.data.Dataset):\n",
    "    def __init__(self, state='training', sub_index=1, transform=None):\n",
    "        \n",
    "        super(Data4Model, self).__init__()\n",
    "        \n",
    "        imgs = np.load('GetData/'+state+'_imgpaths.npy').tolist()\n",
    "        \n",
    "        if state=='training':\n",
    "            n = 16540\n",
    "        else:\n",
    "            n = 200\n",
    "        \n",
    "        mean = np.load('GetData/preprocessed_mean_overall.npy')\n",
    "        std = np.load('GetData/preprocessed_std_overall.npy')\n",
    "        eeg = np.load('preprocessed_eeg_data/sub-'+str(sub_index).zfill(2)+'_'+state+'.npy')\n",
    "        eeg = (eeg-mean[sub_index-1])/std[sub_index-1]\n",
    "        \n",
    "        self.imgs = imgs\n",
    "        self.eeg = eeg\n",
    "        self.transform = transform\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        imgs = self.transform(Image.open(self.imgs[item]).convert('RGB'))\n",
    "        eeg = torch.tensor(self.eeg[item]).float()\n",
    "         \n",
    "        return imgs, eeg\n",
    "\n",
    "# RSA for CORnet\n",
    "cornet_rdms = np.zeros([4, 200, 200])\n",
    "\n",
    "test_dataset = Data4Model(state='test', sub_index=1, transform=transform)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "cornet = CORnet_S().to(device)\n",
    "cornet = torch.nn.DataParallel(cornet)\n",
    "url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "cornet.load_state_dict(ckpt_data['state_dict'])\n",
    "    \n",
    "cornet.eval()\n",
    "    \n",
    "v1 = torch.zeros([200, 200704])\n",
    "v2 = torch.zeros([200, 100352])\n",
    "v4 = torch.zeros([200, 50176])\n",
    "it = torch.zeros([200, 25088])\n",
    "    \n",
    "index = 0\n",
    "for imgs, eeg in test_data_loader:\n",
    "        \n",
    "    imgs = imgs.to(device)\n",
    "    eeg = eeg.to(device)\n",
    "        \n",
    "    imgv1 = cornet.module.V1(imgs)\n",
    "    imgv2 = cornet.module.V2(imgv1)\n",
    "    imgv4 = cornet.module.V4(imgv2)\n",
    "    imgit = cornet.module.IT(imgv4)\n",
    "    v1[index] = imgv1.flatten()\n",
    "    v2[index] = imgv2.flatten()\n",
    "    v4[index] = imgv4.flatten()\n",
    "    it[index] = imgit.flatten()\n",
    "        \n",
    "    index += 1\n",
    "    \n",
    "cornet_rdms[0] = cal_rdm(v1)\n",
    "cornet_rdms[1] = cal_rdm(v2)\n",
    "cornet_rdms[2] = cal_rdm(v4)\n",
    "cornet_rdms[3] = cal_rdm(it)\n",
    "\n",
    "np.save('RSA/CORnet_THINGS_EEG_test_rdms.npy', cornet_rdms)\n",
    "\n",
    "cornet_corrs = np.zeros([10, 4, 60])\n",
    "\n",
    "cornet_rdms = np.load('RSA/CORnet_THINGS_EEG_test_rdms.npy')\n",
    "\n",
    "for sub in range(10):\n",
    "    eegRDMs = np.load('RSA/THINGS_EEG_test/eegrdms_sub'+str(sub+1).zfill(2)+'.npy')[10:70]\n",
    "    for t in range(60):\n",
    "        eegRDM = eegRDMs[t]\n",
    "        for i in range(4):\n",
    "            cornet_rdm = cornet_rdms[i]\n",
    "            cornet_corrs[sub, i, t] = rdm_correlation_spearman(eegRDM, cornet_rdm)[0]\n",
    "\n",
    "np.save('RSA/CORnet_THINGS_EEG_test_RSA_corrs.npy', cornet_corrs)\n",
    "\n",
    "# RSA for ReAlnets\n",
    "realnet_rdms = np.zeros([10, 4, 200, 200])\n",
    "\n",
    "for sub in range(10):\n",
    "    \n",
    "    test_dataset = Data4Model(state='test', sub_index=sub+1, transform=transform)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    realnet = CORnet_S().to(device)\n",
    "    realnet = torch.nn.DataParallel(realnet)\n",
    "    url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "    ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "    \n",
    "    realnet.load_state_dict(ckpt_data['state_dict'])\n",
    "    encoder = Encoder(realnet, 340).to(device)\n",
    "    weights = torch.load('weights/ReAlnet/sub-'+str(sub+1).zfill(2)+'/encoder.pt')\n",
    "    encoder.load_state_dict(weights)\n",
    "    \n",
    "    encoder.eval()\n",
    "    \n",
    "    v1 = torch.zeros([200, 200704])\n",
    "    v2 = torch.zeros([200, 100352])\n",
    "    v4 = torch.zeros([200, 50176])\n",
    "    it = torch.zeros([200, 25088])\n",
    "    \n",
    "    index = 0\n",
    "    for imgs, eeg in test_data_loader:\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        eeg = eeg.to(device)\n",
    "        \n",
    "        imgv1 = encoder.realnet.module.V1(imgs)\n",
    "        imgv2 = encoder.realnet.module.V2(imgv1)\n",
    "        imgv4 = encoder.realnet.module.V4(imgv2)\n",
    "        imgit = encoder.realnet.module.IT(imgv4)\n",
    "        v1[index] = imgv1.flatten()\n",
    "        v2[index] = imgv2.flatten()\n",
    "        v4[index] = imgv4.flatten()\n",
    "        it[index] = imgit.flatten()\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    realnet_rdms[sub, 0] = cal_rdm(v1)\n",
    "    realnet_rdms[sub, 1] = cal_rdm(v2)\n",
    "    realnet_rdms[sub, 2] = cal_rdm(v4)\n",
    "    realnet_rdms[sub, 3] = cal_rdm(it)\n",
    "    \n",
    "    print(sub+1)\n",
    "\n",
    "np.save('RSA/ReAlnet_EEG_THINGS_EEG_test_rdms.npy', realnet_rdms)\n",
    "\n",
    "realnet_corrs = np.zeros([10, 4, 60])\n",
    "\n",
    "realnet_rdms = np.load('RSA/ReAlnet_EEG_THINGS_EEG_test_rdms.npy')\n",
    "\n",
    "for sub in range(10):\n",
    "    eegRDMs = np.load('RSA/THINGS_EEG_test/eegrdms_sub'+str(sub+1).zfill(2)+'.npy')[10:70]\n",
    "    for t in range(60):\n",
    "        eegRDM = eegRDMs[t]\n",
    "        for i in range(4):\n",
    "            realnet_rdm = realnet_rdms[sub, i]\n",
    "            realnet_corrs[sub, i, t] = rdm_correlation_spearman(eegRDM, realnet_rdm)[0]\n",
    "\n",
    "np.save('RSA/ReAlnet_EEG_THINGS_EEG_test_RSA_corrs.npy', realnet_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-fMRI Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data4Model_shen_fmri(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        \n",
    "        super(Data4Model_shen_fmri, self).__init__()\n",
    "        \n",
    "        imgs = np.load('GetData/Shen_fMRI_test_imgpaths.npy').tolist()\n",
    "        \n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        imgs = self.transform(Image.open(self.imgs[item]).convert('RGB'))\n",
    "         \n",
    "        return imgs\n",
    "    \n",
    "# RSA for CORnet\n",
    "cornet_rdms = np.zeros([5, 50, 50])\n",
    "\n",
    "test_dataset = Data4Model_shen_fmri(transform=transform)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "cornet = CORnet_S().to(device)\n",
    "cornet = torch.nn.DataParallel(cornet)\n",
    "url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "cornet.load_state_dict(ckpt_data['state_dict'])\n",
    "    \n",
    "cornet.eval()\n",
    "    \n",
    "v1 = torch.zeros([50, 200704])\n",
    "v2 = torch.zeros([50, 100352])\n",
    "v4 = torch.zeros([50, 50176])\n",
    "it = torch.zeros([50, 25088])\n",
    "avgpool = torch.zeros([50, 512])\n",
    "    \n",
    "index = 0\n",
    "for imgs in test_data_loader:\n",
    "        \n",
    "    imgs = imgs.to(device)\n",
    "        \n",
    "    imgv1 = cornet.module.V1(imgs)\n",
    "    imgv2 = cornet.module.V2(imgv1)\n",
    "    imgv4 = cornet.module.V4(imgv2)\n",
    "    imgit = cornet.module.IT(imgv4)\n",
    "    imgavgpool = cornet.module.decoder.avgpool(imgit)\n",
    "    v1[index] = imgv1.flatten()\n",
    "    v2[index] = imgv2.flatten()\n",
    "    v4[index] = imgv4.flatten()\n",
    "    it[index] = imgit.flatten()\n",
    "    avgpool[index] = imgavgpool.flatten()\n",
    "        \n",
    "    index += 1\n",
    "    \n",
    "cornet_rdms[0] = cal_rdm(v1)\n",
    "cornet_rdms[1] = cal_rdm(v2)\n",
    "cornet_rdms[2] = cal_rdm(v4)\n",
    "cornet_rdms[3] = cal_rdm(it)\n",
    "cornet_rdms[4] = cal_rdm(avgpool)\n",
    "\n",
    "print(cornet_rdms[0, :4, :4])\n",
    "\n",
    "np.save('RSA/CORnet_Shen_fMRI_test_rdms.npy', cornet_rdms)\n",
    "\n",
    "cornet_corrs = np.zeros([3, 5, 5])\n",
    "\n",
    "cornet_rdms = np.load('RDMs/CORnet_Shen_fMRI_test_rdms.npy')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        fmri_rdm = fmri_rdms[i, j]\n",
    "        for k in range(5):\n",
    "            cornet_rdm = cornet_rdms[k]\n",
    "            cornet_corrs[i, j, k] = rdm_correlation_spearman(fmri_rdm, cornet_rdm)[0]\n",
    "\n",
    "np.save('RSA/CORnet_Shen_fMRI_test_RSA_corrs.npy', cornet_corrs)\n",
    "\n",
    "# RSA for ReAlnet\n",
    "realnet_rdms = np.zeros([10, 5, 50, 50])\n",
    "    \n",
    "for sub in range(10):\n",
    "    \n",
    "    test_dataset = Data4Model_shen_fmri(transform=transform)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    realnet = CORnet_S().to(device)\n",
    "    realnet = torch.nn.DataParallel(realnet)\n",
    "    url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "    ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "    \n",
    "    realnet.load_state_dict(ckpt_data['state_dict'])\n",
    "    encoder = Encoder(realnet, 340).to(device)\n",
    "    weights = torch.load('weights/ReAlnet/sub-'+str(sub+1).zfill(2)+'/encoder.pt')\n",
    "    encoder.load_state_dict(weights)\n",
    "    \n",
    "    encoder.eval()\n",
    "    \n",
    "    v1 = torch.zeros([50, 200704])\n",
    "    v2 = torch.zeros([50, 100352])\n",
    "    v4 = torch.zeros([50, 50176])\n",
    "    it = torch.zeros([50, 25088])\n",
    "    avgpool = torch.zeros([50, 512])\n",
    "    \n",
    "    index = 0\n",
    "    for imgs in test_data_loader:\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        imgv1 = encoder.realnet.module.V1(imgs)\n",
    "        imgv2 = encoder.realnet.module.V2(imgv1)\n",
    "        imgv4 = encoder.realnet.module.V4(imgv2)\n",
    "        imgit = encoder.realnet.module.IT(imgv4)\n",
    "        imgavgpool = encoder.realnet.module.decoder.avgpool(imgit)\n",
    "        v1[index] = imgv1.flatten()\n",
    "        v2[index] = imgv2.flatten()\n",
    "        v4[index] = imgv4.flatten()\n",
    "        it[index] = imgit.flatten()\n",
    "        avgpool[index] = imgavgpool.flatten()\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    realnet_rdms[sub, 0] = cal_rdm(v1)\n",
    "    realnet_rdms[sub, 1] = cal_rdm(v2)\n",
    "    realnet_rdms[sub, 2] = cal_rdm(v4)\n",
    "    realnet_rdms[sub, 3] = cal_rdm(it)\n",
    "    realnet_rdms[sub, 4] = cal_rdm(avgpool)\n",
    "    \n",
    "    print(realnet_rdms[sub, 0, :4, :4])\n",
    "    \n",
    "    print(sub+1)\n",
    "\n",
    "np.save('RDMs/ReAlnet_EEG_Shen_fMRI_test_rdms.npy', realnet_rdms)\n",
    "\n",
    "realnet_corrs = np.zeros([3, 5, 10, 5])\n",
    "\n",
    "realnet_rdms = np.load('RSA/ReAlnet_EEG_Shen_fMRI_test_rdms.npy')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        fmri_rdm = fmri_rdms[i, j]\n",
    "        \n",
    "        for sub in range(10):\n",
    "            for k in range(5):\n",
    "                realnet_rdm = realnet_rdms[sub, k]\n",
    "                realnet_corrs[i, j, sub, k] = rdm_correlation_spearman(fmri_rdm, realnet_rdm)[0]\n",
    "\n",
    "np.save('RSA/ReAlnet_Shen_fMRI_test_RSA_corrs.npy', realnet_corrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
