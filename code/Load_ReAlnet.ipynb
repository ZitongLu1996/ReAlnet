{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.utils.model_zoo\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import functools\n",
    "\n",
    "import torchvision.models\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module for flattening input tensor to 1-D for the use in Linear modules\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module that stores the current tensor. Useful for accessing by name\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class CORblock_S(nn.Module):\n",
    "\n",
    "    scale = 4  # scale of the bottleneck convolution channels\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, times=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.times = times\n",
    "\n",
    "        self.conv_input = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.skip = nn.Conv2d(out_channels, out_channels,\n",
    "                              kernel_size=1, stride=2, bias=False)\n",
    "        self.norm_skip = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels * self.scale,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels * self.scale, out_channels * self.scale,\n",
    "                               kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.nonlin2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels * self.scale, out_channels,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.output = Identity()  # for an easy access to this block's output\n",
    "\n",
    "        # need BatchNorm for each time step for training to work well\n",
    "        for t in range(self.times):\n",
    "            setattr(self, f'norm1_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm2_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm3_{t}', nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.conv_input(inp)\n",
    "\n",
    "        for t in range(self.times):\n",
    "            if t == 0:\n",
    "                skip = self.norm_skip(self.skip(x))\n",
    "                self.conv2.stride = (2, 2)\n",
    "            else:\n",
    "                skip = x\n",
    "                self.conv2.stride = (1, 1)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = getattr(self, f'norm1_{t}')(x)\n",
    "            x = self.nonlin1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = getattr(self, f'norm2_{t}')(x)\n",
    "            x = self.nonlin2(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = getattr(self, f'norm3_{t}')(x)\n",
    "\n",
    "            x += skip\n",
    "            x = self.nonlin3(x)\n",
    "            output = self.output(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def CORnet_S():\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('V1', nn.Sequential(OrderedDict([  # this one is custom to save GPU memory\n",
    "            ('conv1', nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                            bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(64)),\n",
    "            ('nonlin1', nn.ReLU(inplace=True)),\n",
    "            ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "            ('conv2', nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1,\n",
    "                            bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(64)),\n",
    "            ('nonlin2', nn.ReLU(inplace=True)),\n",
    "            ('output', Identity())\n",
    "        ]))),\n",
    "        ('V2', CORblock_S(64, 128, times=2)),\n",
    "        ('V4', CORblock_S(128, 256, times=4)),\n",
    "        ('IT', CORblock_S(256, 512, times=2)),\n",
    "        ('decoder', nn.Sequential(OrderedDict([\n",
    "            ('avgpool', nn.AdaptiveAvgPool2d(1)),\n",
    "            ('flatten', Flatten()),\n",
    "            ('linear', nn.Linear(512, 1000)),\n",
    "            ('output', Identity())\n",
    "        ])))\n",
    "    ]))\n",
    "\n",
    "    # weight initialization\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        # nn.Linear is missing here because I originally forgot\n",
    "        # to add it during the training of this network\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, realnet, n_output):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # CORnet\n",
    "        self.realnet = realnet\n",
    "        \n",
    "        # full connected layer\n",
    "        self.fc_v1 = nn.Linear(200704, 128)\n",
    "        self.fc_v2 = nn.Linear(100352, 128)\n",
    "        self.fc_v4 = nn.Linear(50176, 128)\n",
    "        self.fc_it = nn.Linear(25088, 128)\n",
    "        self.fc = nn.Linear(512, n_output)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        \n",
    "        outputs = self.realnet(imgs)\n",
    "        \n",
    "        N = len(imgs)\n",
    "        v1_outputs = self.realnet.module.V1(imgs) # N * 64 * 56 * 56\n",
    "        v2_outputs = self.realnet.module.V2(v1_outputs) # N * 128 * 28 * 28\n",
    "        v4_outputs = self.realnet.module.V4(v2_outputs) # N * 256 * 14 * 14\n",
    "        it_outputs = self.realnet.module.IT(v4_outputs) # N * 512 * 7 * 7\n",
    "        v1_features = self.fc_v1(v1_outputs.view(N, -1))\n",
    "        v1_features = self.activation(v1_features)\n",
    "        v2_features = self.fc_v2(v2_outputs.view(N, -1))\n",
    "        v2_features = self.activation(v2_features)\n",
    "        v4_features = self.fc_v4(v4_outputs.view(N, -1))\n",
    "        v4_features = self.activation(v4_features)\n",
    "        it_features = self.fc_it(it_outputs.view(N, -1))\n",
    "        it_features = self.activation(it_features)\n",
    "        features = torch.cat((v1_features, v2_features, v4_features, it_features), dim=1)\n",
    "        features = self.fc(features)\n",
    "        \n",
    "        return outputs, features\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "subid = 1\n",
    "\n",
    "realnet = CORnet_S().to(device)\n",
    "realnet = torch.nn.DataParallel(realnet)\n",
    "encoder = Encoder(realnet, 340).to(device)\n",
    "weights = torch.load('weights/ReAlnet/sub-'+str(subid).zfill(2)+'/encoder.pt', map_location=device)\n",
    "encoder.load_state_dict(weights)\n",
    "realnet = encoder.realnet\n",
    "\n",
    "# Or you can\n",
    "# realnet = CORnet_S().to(device)\n",
    "# realnet = torch.nn.DataParallel(realnet)\n",
    "# weights = torch.load('weights/ReAlnet/sub-'+str(subid).zfill(2)+'/realnet.pt', map_location=device)\n",
    "# realnet.load_state_dict(weights)\n",
    "\n",
    "realnet.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
