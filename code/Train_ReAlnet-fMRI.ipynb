{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS1467/zitong/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchmetrics.functional import pearson_corrcoef, spearman_corrcoef\n",
    "import torch.utils.model_zoo\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import h5py\n",
    "import random\n",
    "import clip\n",
    "from scipy.stats import spearmanr\n",
    "from torchmetrics.functional.regression import spearman_corrcoef\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as CORnet\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module for flattening input tensor to 1-D for the use in Linear modules\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper module that stores the current tensor. Useful for accessing by name\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class CORblock_S(nn.Module):\n",
    "\n",
    "    scale = 4  # scale of the bottleneck convolution channels\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, times=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.times = times\n",
    "\n",
    "        self.conv_input = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.skip = nn.Conv2d(out_channels, out_channels,\n",
    "                              kernel_size=1, stride=2, bias=False)\n",
    "        self.norm_skip = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(out_channels, out_channels * self.scale,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels * self.scale, out_channels * self.scale,\n",
    "                               kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.nonlin2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels * self.scale, out_channels,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.nonlin3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.output = Identity()  # for an easy access to this block's output\n",
    "\n",
    "        # need BatchNorm for each time step for training to work well\n",
    "        for t in range(self.times):\n",
    "            setattr(self, f'norm1_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm2_{t}', nn.BatchNorm2d(out_channels * self.scale))\n",
    "            setattr(self, f'norm3_{t}', nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.conv_input(inp)\n",
    "\n",
    "        for t in range(self.times):\n",
    "            if t == 0:\n",
    "                skip = self.norm_skip(self.skip(x))\n",
    "                self.conv2.stride = (2, 2)\n",
    "            else:\n",
    "                skip = x\n",
    "                self.conv2.stride = (1, 1)\n",
    "\n",
    "            x = self.conv1(x)\n",
    "            x = getattr(self, f'norm1_{t}')(x)\n",
    "            x = self.nonlin1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = getattr(self, f'norm2_{t}')(x)\n",
    "            x = self.nonlin2(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = getattr(self, f'norm3_{t}')(x)\n",
    "\n",
    "            x += skip\n",
    "            x = self.nonlin3(x)\n",
    "            output = self.output(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def CORnet_S():\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('V1', nn.Sequential(OrderedDict([  # this one is custom to save GPU memory\n",
    "            ('conv1', nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                            bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(64)),\n",
    "            ('nonlin1', nn.ReLU(inplace=True)),\n",
    "            ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "            ('conv2', nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1,\n",
    "                            bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(64)),\n",
    "            ('nonlin2', nn.ReLU(inplace=True)),\n",
    "            ('output', Identity())\n",
    "        ]))),\n",
    "        ('V2', CORblock_S(64, 128, times=2)),\n",
    "        ('V4', CORblock_S(128, 256, times=4)),\n",
    "        ('IT', CORblock_S(256, 512, times=2)),\n",
    "        ('decoder', nn.Sequential(OrderedDict([\n",
    "            ('avgpool', nn.AdaptiveAvgPool2d(1)),\n",
    "            ('flatten', Flatten()),\n",
    "            ('linear', nn.Linear(512, 1000)),\n",
    "            ('output', Identity())\n",
    "        ])))\n",
    "    ]))\n",
    "\n",
    "    # weight initialization\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        # nn.Linear is missing here because I originally forgot\n",
    "        # to add it during the training of this network\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, realnet, n_output):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # CORnet\n",
    "        self.realnet = realnet\n",
    "        \n",
    "        # full connected layer\n",
    "        self.fc_v1 = nn.Linear(200704, 128)\n",
    "        self.fc_v2 = nn.Linear(100352, 128)\n",
    "        self.fc_v4 = nn.Linear(50176, 128)\n",
    "        self.fc_it = nn.Linear(25088, 128)\n",
    "        self.fc = nn.Linear(512, n_output)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        \n",
    "        outputs = self.realnet(imgs)\n",
    "        \n",
    "        N = len(imgs)\n",
    "        v1_outputs = self.realnet.module.V1(imgs) # N * 64 * 56 * 56\n",
    "        v2_outputs = self.realnet.module.V2(v1_outputs) # N * 128 * 28 * 28\n",
    "        v4_outputs = self.realnet.module.V4(v2_outputs) # N * 256 * 14 * 14\n",
    "        it_outputs = self.realnet.module.IT(v4_outputs) # N * 512 * 7 * 7\n",
    "        v1_features = self.fc_v1(v1_outputs.view(N, -1))\n",
    "        v1_features = self.activation(v1_features)\n",
    "        v2_features = self.fc_v2(v2_outputs.view(N, -1))\n",
    "        v2_features = self.activation(v2_features)\n",
    "        v4_features = self.fc_v4(v4_outputs.view(N, -1))\n",
    "        v4_features = self.activation(v4_features)\n",
    "        it_features = self.fc_it(it_outputs.view(N, -1))\n",
    "        it_features = self.activation(it_features)\n",
    "        features = torch.cat((v1_features, v2_features, v4_features, it_features), dim=1)\n",
    "        features = self.fc(features)\n",
    "        \n",
    "        return outputs, features\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# this cornet will be used for getting imagenet-based outputs as the classification targets\n",
    "cornet = CORnet_S().to(device)\n",
    "cornet = torch.nn.DataParallel(cornet)\n",
    "url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "cornet.load_state_dict(ckpt_data['state_dict'])\n",
    "\n",
    "# this FAnet is what we are going to train\n",
    "realnet = CORnet_S().to(device)\n",
    "realnet = torch.nn.DataParallel(realnet)\n",
    "url = f'https://s3.amazonaws.com/cornet-models/cornet_s-1d3f7974.pth'\n",
    "ckpt_data = torch.utils.model_zoo.load_url(url)\n",
    "realnet.load_state_dict(ckpt_data['state_dict'])\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "class Data4Model(torch.utils.data.Dataset):\n",
    "    def __init__(self, state='train', sub_index=1, transform=None):\n",
    "        \n",
    "        super(Data4Model, self).__init__()\n",
    "        \n",
    "        imgs = ('image/Shen_fMRI/'+state+'/'+np.load('data/Shen_fMRI/'+state+'/imgpaths.npy', allow_pickle=True)).tolist()\n",
    "        \n",
    "        if state=='train':\n",
    "            n = 1200\n",
    "        else:\n",
    "            n = 50\n",
    "            \n",
    "        fmri = np.load('data/Shen_fMRI/'+state+'/sub-'+str(sub_index).zfill(2)+'_avg_1024d.npy')\n",
    "        \n",
    "        labels = np.load('data/Shen_fMRI/'+state+'/imagenet_labels.npy')\n",
    "        \n",
    "        self.imgs = imgs\n",
    "        self.fmri = fmri\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        imgs = self.transform(Image.open(self.imgs[item]).convert('RGB'))\n",
    "        fmri = torch.tensor(self.fmri[item]).float()\n",
    "        labels = torch.tensor(self.labels[item])\n",
    "         \n",
    "        return imgs, fmri, labels\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "task_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "mse_criterion = nn.MSELoss()\n",
    "\n",
    "class Gen_criterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, eeg, criterion):\n",
    "    \n",
    "        loss1 = criterion(pred, eeg)\n",
    "    \n",
    "        pos_corr = []\n",
    "        neg_corr = []\n",
    "        n = pred.shape[0]\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    pos_corr.append(pearson_corrcoef(pred[i], eeg[j]))\n",
    "                else:\n",
    "                    neg_corr.append(pearson_corrcoef(pred[i], eeg[j]))\n",
    "        loss2 = 1 - torch.mean(torch.tensor(pos_corr)) + torch.mean(torch.tensor(neg_corr))\n",
    "        loss = loss1 + loss2\n",
    "        return loss\n",
    "\n",
    "gen_criterion = Gen_criterion()\n",
    "\n",
    "\n",
    "def train_and_test(encoder, cornet, weightspath, task_criterion, mse_criterion, gen_criterion, optimizer, transform,\n",
    "                   beta=0.5, sub_index=1, batchsize=64, num_epochs=100):\n",
    "\n",
    "    train_dataset = Data4Model(state='training', sub_index=sub_index, transform=transform)\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    test_dataset = Data4Model(state='test', sub_index=sub_index, transform=transform)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=batchsize, shuffle=False)\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    loss_save = np.zeros([num_epochs, 6])\n",
    "\n",
    "    best_model_params_path = os.path.join(weightspath + 'best_model_params.pt')\n",
    "\n",
    "    cornet.eval()\n",
    "    \n",
    "    best_corr = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "    \n",
    "        # Training Session\n",
    "    \n",
    "        encoder.train()\n",
    "            \n",
    "        running_loss1 = 0.0\n",
    "        running_loss2 = 0.0\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        # Iterate over data.\n",
    "        \n",
    "        niterates = 0\n",
    "\n",
    "        for imgs, eeg in tqdm(train_data_loader):\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            eeg = eeg.to(device)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # forward\n",
    "            outputs, pred = encoder(imgs)\n",
    "            targets = torch.argmax(cornet(imgs), dim=1)\n",
    "            loss1 = task_criterion(outputs, targets)\n",
    "            loss2 = gen_criterion(pred, eeg, mse_criterion)\n",
    "            loss = beta*loss2 + loss1\n",
    "        \n",
    "            # backward + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss1 += loss1.item()\n",
    "            running_loss2 += loss2.item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            niterates += 1\n",
    "        \n",
    "        loss_save[epoch, 0] = running_loss1/niterates\n",
    "        loss_save[epoch, 1] = running_loss2/niterates\n",
    "        loss_save[epoch, 2] = running_loss/niterates\n",
    "            \n",
    "        print(f'Train Loss: {running_loss/niterates:.4f} Task Loss: {running_loss1/niterates:.4f} Enc Loss: {running_loss2/niterates:.4f}')\n",
    "    \n",
    "        # Test Session\n",
    "    \n",
    "        encoder.eval()\n",
    "        \n",
    "        running_loss1 = 0.0\n",
    "        running_loss2 = 0.0\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        # Iterate over data.\n",
    "        \n",
    "        niterates = 0\n",
    "\n",
    "        for imgs, eeg in tqdm(test_data_loader):\n",
    "            \n",
    "            imgs = imgs.to(device)\n",
    "            eeg = eeg.to(device)\n",
    "        \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # forward\n",
    "            outputs, pred = encoder(imgs)\n",
    "            targets = torch.argmax(cornet(imgs), dim=1)\n",
    "            loss1 = task_criterion(outputs, targets)\n",
    "            loss2 = gen_criterion(pred, eeg, mse_criterion)\n",
    "            loss = beta*loss2 + loss1\n",
    "            \n",
    "            running_loss1 += loss1.item()\n",
    "            running_loss2 += loss2.item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            niterates += 1\n",
    "        \n",
    "        loss_save[epoch, 3] = running_loss1/niterates\n",
    "        loss_save[epoch, 4] = running_loss2/niterates\n",
    "        loss_save[epoch, 5] = running_loss/niterates\n",
    "            \n",
    "        print(f'Test Loss: {running_loss/niterates:.4f} Task Loss: {running_loss1/niterates:.4f} Enc Loss: {running_loss2/niterates:.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss/niterates\n",
    "        \n",
    "        if epoch == 0:\n",
    "            best_loss = epoch_loss\n",
    "        \n",
    "        # deep copy the model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(encoder.state_dict(), best_model_params_path)\n",
    "            \n",
    "        epoch_model_params_path = os.path.join(weightspath + 'epoch'+str(epoch)+'_model_params.pt')\n",
    "        torch.save(encoder.state_dict(), epoch_model_params_path)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    \n",
    "    np.savetxt(weightspath + 'loss.txt', loss_save)\n",
    "    \n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best test Loss: {best_loss:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2024)\n",
    "    \n",
    "encoder = Encoder(realnet, 1024).to(device)\n",
    "\n",
    "\n",
    "subid = 1\n",
    "\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.00002)\n",
    "train_and_test(encoder, cornet, '/fs/scratch/PAS1467/ReAlnet/ReAlnet_fMRI_100/sub-'+str(subid).zfill(2)+'/',\n",
    "               task_criterion, mse_criterion, gen_criterion, optimizer, transform, beta=100,\n",
    "               sub_index=subid, batchsize=16, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
